(* this is also code of the scarpy app which is used to scrape data from the Books.to.scrape.com but this code will extract multipl pages of the website or it will not save in Mongodb database system . *)

import scrapy
from scrapy.linkextractors import LinkExtractor
from scrapy.spiders import Rule , CrawlSpider


class WebSpiderSpider(CrawlSpider):
    name = "web_spider"
    allowed_domains = ["books.toscrape.com"]
    start_urls = ["https://books.toscrape.com/"]
    base_url = "https://books.toscrape.com/"
    rules = [Rule(LinkExtractor (restrict_xpaths="//li[@class = 'next' or @class = 'previous']"),
    callback="parse", follow=True)]

    def parse(self, response):
        # Fixed the XPath expression and loop
        for link in response.xpath("//article[@class='product_pod']/h3/a/@href").extract():
            # Fixed the yield statement to follow the link correctly
            yield response.follow(link, self.product_parse)

    def product_parse(self, response):
        # Correctly yield a dictionary with the title
            yield {
            "title": response.xpath('//h1/text()').get().strip(),
            "price": response.xpath("//p[@class='price_color']/text()").get().strip(),
            "rating": response.xpath("//p[contains(@class, 'star-rating')]/@class").get().split()[-1],
            "decription": response.xpath("//article[@class = 'product_page']/p/text()").get(),            
            "UPC" : response.xpath("//table//tr[1]/td/text()").get(),
            "Product Type" : response.xpath("//table//tr[2]/td/text()").get(),
            "Price (excl. tax)" : response.xpath("//table//tr[3]/td/text()").get(),
            "Price (incl. tax)" : response.xpath("//table//tr[4]/td/text()").get(),
            "Tax" : response.xpath("//table//tr[5]/td/text()").get(),
            "Availability" : response.xpath("//table//tr[6]/td/text()").get(),
            "Number of reviews" : response.xpath("//table//tr[7]/td/text()").get()
        }



